This project uses opensource llm Ollama3 and llamaindex framework. 


Steps to setup:

To download the Llama3 model just do ollama pull llama3.
To download the nomic embeddings, just do ollama pull nomic-embed-text

To import llama_index.llms.ollama, you should run pip install llama-index-llms-ollama.
To import llama_index.embeddings.ollama, you should run pip install llama-index-embeddings-ollama.


NOTE: You will need a machine with at least 32GB of RAM.